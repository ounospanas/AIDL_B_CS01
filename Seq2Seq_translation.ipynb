{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Seq2Seq_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ounospanas/AIDL_B_CS01/blob/main/Seq2Seq_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgKXkL6PeJbG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7604502e-3bf9-4f54-9484-bbaf39a8850a"
      },
      "source": [
        "\"\"\"\n",
        "The MIT License (MIT)\n",
        "Copyright (c) 2021 NVIDIA\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "this software and associated documentation files (the \"Software\"), to deal in\n",
        "the Software without restriction, including without limitation the rights to\n",
        "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
        "the Software, and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
        "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
        "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
        "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThe MIT License (MIT)\\nCopyright (c) 2021 NVIDIA\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\\nthe Software, and to permit persons to whom the Software is furnished to do so,\\nsubject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAckx_DreJbI"
      },
      "source": [
        "This code example demonstrates how to build a neural machine translation network. It is a sequence-to-sequence network based on an encoder-decoder architecture. More context for this code example can be found in the section \"Programming Example: Neural Machine Translation\" in Chapter 14 in the book Learning Deep Learning by Magnus Ekman (ISBN: 9780137470358).\n",
        "\n",
        "The data used to train the model is expected to be in the file ../data/fra.txt.\n",
        "We begin by importing modules that we need for the program. Just like in c12e1_autocomplete_embedding we use some functionality from TensorFlow to preprocess text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sXa30DieJbJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text \\\n",
        "    import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence \\\n",
        "    import pad_sequences\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmuvUUAzeJbK"
      },
      "source": [
        "Next, we define some constants. We specify a vocabulary size of 10,000 symbols, out of which four indices are reserved for padding, out-of-vocabulary words (denoted as UNK), START tokens, and STOP tokens. Our training corpus is large, so we set the parameter READ_LINES to the number of lines in the input file we want to use in our example (60,000). Our layers consist of 256 units (LAYER_SIZE), and the embedding layers output 128 dimensions (EMBEDDING_WIDTH). We use 20% (TEST_PERCENT) of the dataset as test set and further select 20 sentences (SAMPLE_SIZE) to inspect in detail during training. We limit the length of the source and destination sentences to, at most, 60 words (MAX_LENGTH). Finally, we provide the path to the data file, where each line is expected to contain two versions of the same sentence (one in each language) separated by a tab character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQrF8FAveJbK"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "MAX_WORDS = 10000\n",
        "READ_LINES = 60000\n",
        "LAYER_SIZE = 256\n",
        "EMBEDDING_WIDTH = 128\n",
        "TEST_PERCENT = 0.2\n",
        "SAMPLE_SIZE = 20\n",
        "OOV_WORD = 'UNK'\n",
        "PAD_INDEX = 0\n",
        "OOV_INDEX = 1\n",
        "START_INDEX = MAX_WORDS - 2\n",
        "STOP_INDEX = MAX_WORDS - 1\n",
        "MAX_LENGTH = 60\n",
        "SRC_DEST_FILE_NAME = 'data/fra.txt'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqMbz0epeJbK"
      },
      "source": [
        "The next code snippet shows the function used to read the input data file and do some initial processing. Each line is split into two strings, where the first contains the sentence in the destination language and the second contains the sentence in the source language. We use the function text_to_word_sequence() to clean the data somewhat (make everything lowercase and remove punctuation) and split each sentence into a list of individual words. If the list (sentence) is longer than the maximum allowed length, then it is truncated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9WoRCC7eJbL"
      },
      "source": [
        "# Function to read file.\n",
        "def read_file_combined(file_name, max_len):\n",
        "    file = open(file_name, 'r', encoding='utf-8')\n",
        "    src_word_sequences = []\n",
        "    dest_word_sequences = []\n",
        "    for i, line in enumerate(file):\n",
        "        if i == READ_LINES:\n",
        "            break\n",
        "        pair = line.split('\\t')\n",
        "        word_sequence = text_to_word_sequence(pair[1])\n",
        "        src_word_sequence = word_sequence[0:max_len]\n",
        "        src_word_sequences.append(src_word_sequence)\n",
        "        word_sequence = text_to_word_sequence(pair[0])\n",
        "        dest_word_sequence = word_sequence[0:max_len]\n",
        "        dest_word_sequences.append(dest_word_sequence)\n",
        "    file.close()\n",
        "    return src_word_sequences, dest_word_sequences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLLmphLFeJbM"
      },
      "source": [
        "The next code snippet shows functions used to turn sequences of words into\n",
        "sequences of tokens, and vice versa. We call tokenize() a single time for each\n",
        "language, so the argument sequences is a list of lists where each of the inner\n",
        "lists represents a sentence. The Tokenizer class assigns indices to the most\n",
        "common words and returns either these indices or the reserved OOV_INDEX\n",
        "for less common words that did not make it into the vocabulary. We tell the\n",
        "Tokenizer to use a vocabulary of 9998 (MAX_WORDS-2)—that is, use only\n",
        "indices 0 to 9997, so that we can use indices 9998 and 9999 as our START and\n",
        "STOP tokens (the Tokenizer does not support the notion of START and STOP\n",
        "tokens but does reserve index 0 to use as a padding token and index 1 for outof-\n",
        "vocabulary words). Our tokenize() function returns both the tokenized\n",
        "sequence and the Tokenizer object itself. This object will be needed anytime we\n",
        "want to convert tokens back into words.\n",
        "\n",
        "The function tokens_to_words() requires a Tokenizer and a list of indices. We simply check for the reserved indices: If we find a match, we replace them with hardcoded strings, and if we find no match, we let the Tokenizer convert the index to the corresponding word string. The Tokenizer expects a list of lists of indices and returns a list of strings, which is why we need to call it with [[index]] and then select the 0th element to arrive at a string.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wycEnGBoeJbR"
      },
      "source": [
        "# Functions to tokenize and un-tokenize sequences.\n",
        "def tokenize(sequences):\n",
        "    # \"MAX_WORDS-2\" used to reserve two indices\n",
        "    # for START and STOP.\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS-2,\n",
        "                          oov_token=OOV_WORD)\n",
        "    tokenizer.fit_on_texts(sequences)\n",
        "    token_sequences = tokenizer.texts_to_sequences(sequences)\n",
        "    return tokenizer, token_sequences\n",
        "\n",
        "def tokens_to_words(tokenizer, seq):\n",
        "    word_seq = []\n",
        "    for index in seq:\n",
        "        if index == PAD_INDEX:\n",
        "            word_seq.append('PAD')\n",
        "        elif index == OOV_INDEX:\n",
        "            word_seq.append(OOV_WORD)\n",
        "        elif index == START_INDEX:\n",
        "            word_seq.append('START')\n",
        "        elif index == STOP_INDEX:\n",
        "            word_seq.append('STOP')\n",
        "        else:\n",
        "            word_seq.append(tokenizer.sequences_to_texts(\n",
        "                [[index]])[0])\n",
        "    print(word_seq)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNoqol-deJbS"
      },
      "source": [
        "Given these helper functions, it is trivial to read the input data\n",
        "file and convert into tokenized sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ9f4r9ieJbS"
      },
      "source": [
        "# Read file and tokenize.\n",
        "src_seq, dest_seq = read_file_combined(SRC_DEST_FILE_NAME,\n",
        "                                       MAX_LENGTH)\n",
        "src_tokenizer, src_token_seq = tokenize(src_seq)\n",
        "dest_tokenizer, dest_token_seq = tokenize(dest_seq)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlbSnhvteJbS"
      },
      "source": [
        "It is now time to arrange the data into arrays that can be used for training and testing. The following example provides some insight into what we need as input and output for a single training example, where src_input is the input to the encoder network, dest_input is the input to the decoder network, and dest_target is the desired output from the decoder network:\n",
        "\n",
        "src_input = [PAD, PAD, PAD, id(\"je\"), id(\"suis\"), id(\"étudiant\")]\n",
        "dest_input = [START, id(\"i\"), id(\"am\"), id(\"a\"), id(\"student\"), STOP, PAD, PAD]\n",
        "dest_target = [one_hot_id(\"i\"), one_hot_id(\"am\"), one_hot_id(\"a\"), one_hot_id(\"student\"), one_hot_id(STOP), one_hot_id(PAD), one_hot_id(PAD), one_hot_id(PAD)]\n",
        "\n",
        "In the example, id(string) refers to the tokenized index of the string, and one_hot_id is the one-hot encoded version of the index. We have assumed that the longest source sentence is six words, so we padded src_input to be of that length. Similarly, we have assumed that the longest destination sentence is eight words including START and STOP tokens, so we padded both dest_input and dest_target to be of that length. Note how the symbols in dest_input are offset by one location compared to the symbols in dest_target because when we later do inference, the inputs into the decoder network will be coming from the output of the network for the previous timestep. Although this example has shown the training example as being lists, in reality, they will be rows in NumPy arrays, where each array contains multiple training examples.\n",
        "\n",
        "The padding is done to ensure that we can use mini-batches for training. That is, all source sentences need to be the same length, and all destination sentences need to be the same length. We pad the source input at the beginning (known as prepadding) and the destination at the end (known as postpadding), which is nonobvious.\n",
        "\n",
        "We previously stated that when using padding, the model can learn to ignore the padded values. However, as always, things are not as simple as they might appear. Although the model can learn to ignore values, it will not perfectly learn this. The ease with which it learns to ignore padding values might depend on how the data is arranged. It is not hard to imagine that inputting a considerable number of zeros at the end of a sequence will dilute the input and affect the internal state of the network. From that perspective, it makes sense to pad the input values with zeros in the beginning of the sequence instead. Similarly, in a sequence-to-sequence network, if the encoder has created an internal state that is transferred to the decoder, diluting this state by presenting a number of zeros before the START token also seems like it could be bad. This reasoning supports the chosen padding (prepadding of the source input and postpadding of the destination input).\n",
        "\n",
        "The code snippet below shows a compact way of creating the three arrays that we need. The first two lines create two new lists, each containing the destination sequences but the first (dest_target_token_seq) also augmented with STOP_INDEX after each sequence and the second (dest_input_token_seq) augmented with both START_INDEX and STOP_INDEX. It is easy to miss that dest_input_token_seq has a STOP_INDEX, but that falls out naturally because it is created from the dest_target_token_seq for which a STOP_INDEX was just added to each sentence.\n",
        "\n",
        "Next, we call pad_sequences() on both the original src_input_data list (of lists) and on these two new destination lists. The pad_sequences() function pads the sequences with the PAD value and then returns a NumPy array. The default behavior of pad_sequences is to do prepadding, and we do that for the source sequence but explicitly ask for postpadding for the destination sequences.\n",
        "\n",
        "We conclude with converting the data type to np.int64 to match what PyTorch later requires.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0UnnyoeJbT"
      },
      "source": [
        "# Prepare training data.\n",
        "dest_target_token_seq = [x + [STOP_INDEX] for x in dest_token_seq]\n",
        "dest_input_token_seq = [[START_INDEX] + x for x in\n",
        "                        dest_target_token_seq]\n",
        "src_input_data = pad_sequences(src_token_seq)\n",
        "dest_input_data = pad_sequences(dest_input_token_seq,\n",
        "                                padding='post')\n",
        "dest_target_data = pad_sequences(\n",
        "    dest_target_token_seq, padding='post', maxlen\n",
        "    = len(dest_input_data[0]))\n",
        "\n",
        "# Convert to same precision as model.\n",
        "src_input_data = src_input_data.astype(np.int64)\n",
        "dest_input_data = dest_input_data.astype(np.int64)\n",
        "dest_target_data = dest_target_data.astype(np.int64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb-KCInxeJbT"
      },
      "source": [
        "The next code snippet demonstrates how we can manually split our dataset into a training dataset and a test dataset. We split the dataset by first creating a list test_indices, which contains a 20% (TEST_PERCENT) subset of all the numbers from 0 to N−1, where N is the size of our original dataset. We then create a list train_indices, which contains the remaining 80%. We can now use these lists to select a number of rows in the arrays representing the dataset and create two new collections of arrays, one to be used as training set and one to be used as test set. Finally, we create a third collection of arrays, which only contains 20 (SAMPLE_SIZE) random examples from the test dataset. We will use them to inspect the resulting translations in detail, but since that is a manual process, we limit ourselves to a small number of sentences.\n",
        "\n",
        "Finally, we convert the NumPy arrays to PyTorch tensors and create Dataset objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9h8mkRYeJbT"
      },
      "source": [
        "# Split into training and test set.\n",
        "rows = len(src_input_data[:,0])\n",
        "all_indices = list(range(rows))\n",
        "test_rows = int(rows * TEST_PERCENT)\n",
        "test_indices = random.sample(all_indices, test_rows)\n",
        "train_indices = [x for x in all_indices if x not in test_indices]\n",
        "\n",
        "train_src_input_data = src_input_data[train_indices]\n",
        "train_dest_input_data = dest_input_data[train_indices]\n",
        "train_dest_target_data = dest_target_data[train_indices]\n",
        "\n",
        "test_src_input_data = src_input_data[test_indices]\n",
        "test_dest_input_data = dest_input_data[test_indices]\n",
        "test_dest_target_data = dest_target_data[test_indices]\n",
        "\n",
        "# Create a sample of the test set that we will inspect in detail.\n",
        "test_indices = list(range(test_rows))\n",
        "sample_indices = random.sample(test_indices, SAMPLE_SIZE)\n",
        "sample_input_data = test_src_input_data[sample_indices]\n",
        "sample_target_data = test_dest_target_data[sample_indices]\n",
        "\n",
        "# Create Dataset objects.\n",
        "trainset = TensorDataset(torch.from_numpy(train_src_input_data),\n",
        "                         torch.from_numpy(train_dest_input_data),\n",
        "                         torch.from_numpy(train_dest_target_data))\n",
        "testset = TensorDataset(torch.from_numpy(test_src_input_data),\n",
        "                         torch.from_numpy(test_dest_input_data),\n",
        "                         torch.from_numpy(test_dest_target_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoqZDRQKeJbU"
      },
      "source": [
        "We are now ready to build our model. It consists of an encoder part and a decoder part (see Figures 14-4 and 14-5 in Chapter 14). The encoder consists of an embedding layer and two LSTM layers. The decoder consists of an embedding layer, two LSTM layers, and a fully connected softmax layer. We define these as two separate models, but we will use them together as an encoder-decoder model.\n",
        "\n",
        "The code snippet below contains the implementation of the encoder model. One thing to note is that it will output the full output from the LSTM object. That is, it will output a tuple containing both output state and internal state for all layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESYZZJdPeJbU"
      },
      "source": [
        "# Define models.\n",
        "class EncoderModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(MAX_WORDS, EMBEDDING_WIDTH)\n",
        "        nn.init.uniform_(self.embedding_layer.weight, -0.05, 0.05) # Default is -1, 1.\n",
        "        self.lstm_layers = nn.LSTM(EMBEDDING_WIDTH, LAYER_SIZE, num_layers=2, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        x = self.lstm_layers(x)\n",
        "        # we need the states not the output\n",
        "        return x[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doLU6-4b3c2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f8c8ec-f041-473c-96a2-a9a69ecf7f2b"
      },
      "source": [
        "encoder_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderModel(\n",
              "  (embedding_layer): Embedding(10000, 128)\n",
              "  (lstm_layers): LSTM(128, 256, num_layers=2, batch_first=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUM9VWgleJbU"
      },
      "source": [
        "The next code snippet shows the implementation of the decoder model. In addition to the sentence in the destination language, it needs the output state from the encoder model. We use the same mechanism as in c12e1_autocomplete_embedding to manage the input state.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSpeJNo-eJbU"
      },
      "source": [
        "class DecoderModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.state = None\n",
        "        # we will call the LSTM layers with just x and state. This implies that the LSTM module will not use 0 \n",
        "        # as initial h and c states. However, we will supply the variable self.state as input to the LSTM layers. \n",
        "        # In that case the LSTM layers will use these states as their initial states instead of 0.\n",
        "        self.use_state = False\n",
        "        self.embedding_layer = nn.Embedding(MAX_WORDS, EMBEDDING_WIDTH)\n",
        "        nn.init.uniform_(self.embedding_layer.weight, -0.05, 0.05)\n",
        "        #For the model, we start with declaring an Embedding layer with MAX_WORDS as input size and \n",
        "        # EMBEDDING_WIDTH as output size. We adjust the weight initialization to use \n",
        "        #uniform random numbers between -0.05 and 0.05, as opposed to the default range of -1.0 to 1.0. \n",
        "        #We did this to match the range used in our TensorFlow examples.\n",
        "        self.lstm_layers = nn.LSTM(EMBEDDING_WIDTH, LAYER_SIZE, num_layers=2, batch_first=True)\n",
        "        self.output_layer = nn.Linear(LAYER_SIZE, MAX_WORDS)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        if(self.use_state):\n",
        "            x = self.lstm_layers(x, self.state)\n",
        "        else:\n",
        "            x = self.lstm_layers(x)\n",
        "        # use it for the next time step\n",
        "        # apart from calling detach() -  declared not to need gradients - we also call clone(), \n",
        "        # which makes a copy of the state \n",
        "        # so it does not change under the hood by the layers themselves if they are later \n",
        "        # called with new inputs.\n",
        "        self.state = (x[1][0].detach().clone(), x[1][1].detach().clone()) # Store most recent internal state.\n",
        "        x = self.output_layer(x[0])\n",
        "        return x\n",
        "\n",
        "    # Functions to provide explicit control of LSTM state.\n",
        "    def set_state(self, state):\n",
        "        self.state = state\n",
        "        self.use_state = True\n",
        "        return\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.state\n",
        "\n",
        "    def clear_state(self):\n",
        "        self.use_state = False\n",
        "        return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TrLsusFeJbV"
      },
      "source": [
        "The next code snippet instantitates the two models, and creates two optimizers, one for each model. We decided to use RMSProp as optimizer because some experiments indicate that it performs better than Adam for this specific model. We use CrossEntropyLoss as usual.\n",
        "\n",
        "We transfer the models to the GPU and create a DataLoader object for both the training and test dataset. We have not had to do this lately because it has been included in our train_model funtion that was reused for all recent examples. We cannot use that function in this example because it does not support the more complex encoder-decoder model that we want to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1nURiM0eJbV"
      },
      "source": [
        "encoder_model = EncoderModel()\n",
        "decoder_model = DecoderModel()\n",
        "\n",
        "# Loss functions and optimizer.\n",
        "encoder_optimizer = torch.optim.RMSprop(encoder_model.parameters(), lr=0.001)\n",
        "decoder_optimizer = torch.optim.RMSprop(decoder_model.parameters(), lr=0.001)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Using a custom training loop instead of our standard training function.\n",
        "# Transfer model to GPU.\n",
        "encoder_model.to(device)\n",
        "decoder_model.to(device)\n",
        "\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVcIN0EHeJbV"
      },
      "source": [
        "The final code snippet shows hos to train and test the model. It is a modified version of the training loop that we had implemented in the train_model function (see utilities.py for comparison). We focus on describing the differences.\n",
        "\n",
        "We need to set both the encoder and decoder model in training mode by calling the train() method. The same applies for the calls to zero_grad() and step() on the optimizers. Additionally, our DataLoader objects will now return two sets of inputs (src_inputs and dest_inputs) to supply input values both to the encoder and decoder models.\n",
        "\n",
        "For the forward pass we first invoke the encoder model. We then read out its state and use that to set the state for the decoder model, followed by invoking the decoder model as well.\n",
        "\n",
        "We have also modified how the accuracy metric is calculated. As described in the book, accuracy is not necessarily a meaningful metric for machine translation (BLEU score is better) and one can also envision different ways of computing accuracy. The way we compute it in this example is that we determine how many of the words match the expected targets, instead of looking at if a sentence fully matches the target sentence. We chose to compute it this way to match what is automatically computed in the TensorFlow version of this code example.\n",
        "\n",
        "The second inner loop below evaluates the model on the test dataset. Just as in our usual train_model function, this loop largely mimics the first inner loop but without running a backward pass and adjusting weights.\n",
        "\n",
        "We then move on to a third inner loop below that was not present in our train_model function. This loop uses the model to produce and print out translations for our 20 sample examples. We do this to gain some insight into what the translations look like. We first invoke the encoder model with the sentence to translate and retrieve the model internal state. We then use this internal state as a starting point for the decoder to generate a translation, using the START token as input for the first time step. The loop that generates the translation is very similar to the code in c12e1_autocomplete_embedding. After all, the decoder is no different than a language model that generates a sentence based on an encoder-generated initial state representing the sentence to translate. The loop iterates until the model produces a STOP token or until a given number of words have been produced. Finally, we convert the produced tokenized sequences into the corresponding word sequences and print them out.\n",
        "\n",
        "See the section \"Experimental results\" in Chapter 14 for examples of translations that were generated by an equivalent TensorFlow implementation of this code example, as well as a discussion about the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAabIw-veJbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8ad3e0-c786-40b0-e424-0c15d414ceec"
      },
      "source": [
        "# Train and test repeatedly.\n",
        "for i in range(EPOCHS):\n",
        "    encoder_model.train() # Set model in training mode.\n",
        "    decoder_model.train() # Set model in training mode.\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_batches = 0\n",
        "    train_elems = 0\n",
        "    for src_inputs, dest_inputs, dest_targets in trainloader:\n",
        "        # Move data to GPU.\n",
        "        src_inputs, dest_inputs, dest_targets = src_inputs.to(\n",
        "            device), dest_inputs.to(device), dest_targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients.\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass.\n",
        "        encoder_state = encoder_model(src_inputs)\n",
        "        decoder_model.set_state(encoder_state)\n",
        "        outputs = decoder_model(dest_inputs)\n",
        "        loss = loss_function(outputs.view(-1, MAX_WORDS), dest_targets.view(-1))\n",
        "        # Accumulate metrics.\n",
        "        _, indices = torch.max(outputs.data, 2)\n",
        "        train_correct += (indices == dest_targets).sum().item()\n",
        "        train_elems += indices.numel()\n",
        "        train_batches +=  1\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backward pass and update.\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "    train_loss = train_loss / train_batches\n",
        "    train_acc = train_correct / train_elems\n",
        "\n",
        "    # Evaluate the model on the test dataset.\n",
        "    encoder_model.eval() # Set model in inference mode.\n",
        "    decoder_model.eval() # Set model in inference mode.\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_batches = 0\n",
        "    test_elems = 0\n",
        "    for src_inputs, dest_inputs, dest_targets in testloader:\n",
        "        # Move data to GPU.\n",
        "        src_inputs, dest_inputs, dest_targets = src_inputs.to(\n",
        "            device), dest_inputs.to(device), dest_targets.to(device)\n",
        "        encoder_state = encoder_model(src_inputs)\n",
        "        decoder_model.set_state(encoder_state)\n",
        "        outputs = decoder_model(dest_inputs)\n",
        "        loss = loss_function(outputs.view(-1, MAX_WORDS), dest_targets.view(-1))\n",
        "        _, indices = torch.max(outputs, 2)\n",
        "        test_correct += (indices == dest_targets).sum().item()\n",
        "        test_elems += indices.numel()\n",
        "        test_batches +=  1\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    test_loss = test_loss / test_batches\n",
        "    test_acc = test_correct / test_elems\n",
        "    print(f'Epoch {i+1}/{EPOCHS} loss: {train_loss:.4f} - acc: {train_acc:0.4f} - val_loss: {test_loss:.4f} - val_acc: {test_acc:0.4f}')\n",
        "\n",
        "    # Loop through samples to see result\n",
        "    for (test_input, test_target) in zip(sample_input_data,\n",
        "                                         sample_target_data):\n",
        "        # Run a single sentence through encoder model.\n",
        "        x = np.reshape(test_input, (1, -1))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        inputs = inputs.to(device)\n",
        "        last_states = encoder_model(inputs)\n",
        "\n",
        "        # Provide resulting state and START_INDEX as input\n",
        "        # to decoder model.\n",
        "        decoder_model.set_state(last_states)\n",
        "        prev_word_index = START_INDEX\n",
        "        produced_string = ''\n",
        "        pred_seq = []\n",
        "        for j in range(MAX_LENGTH):\n",
        "            x = np.reshape(np.array(prev_word_index), (1, 1))\n",
        "            # Predict next word and capture internal state.\n",
        "            inputs = torch.from_numpy(x)\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = decoder_model(inputs)\n",
        "            preds = outputs.cpu().detach().numpy()[0][0]\n",
        "            state = decoder_model.get_state()\n",
        "            decoder_model.set_state(state)\n",
        "\n",
        "            # Find the most probable word.\n",
        "            prev_word_index = preds.argmax()\n",
        "            pred_seq.append(prev_word_index)\n",
        "            if prev_word_index == STOP_INDEX:\n",
        "                break\n",
        "        tokens_to_words(src_tokenizer, test_input)\n",
        "        tokens_to_words(dest_tokenizer, test_target)\n",
        "        tokens_to_words(dest_tokenizer, pred_seq)\n",
        "        print('\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 loss: 2.4011 - acc: 0.6224 - val_loss: 2.0072 - val_acc: 0.6658\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"can't\", 'be', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'day', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'have', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'have', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'have', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'have', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['this', 'is', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'day', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 2/20 loss: 1.7678 - acc: 0.6934 - val_loss: 1.6444 - val_acc: 0.7164\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'confused', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"can't\", 'be', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'can', 'help', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'be', 'careful', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'hungry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'out', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'very', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['stop', 'out', 'of', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'careful', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['what', 'are', 'your', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'different', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'your', 'room', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'made', 'me', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 3/20 loss: 1.4523 - acc: 0.7329 - val_loss: 1.4729 - val_acc: 0.7397\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'confused', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"can't\", 'see', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['where', 'is', 'he', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'bit', 'person', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'saw', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'needed', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"isn't\", 'crying', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'to', 'die', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'naive', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'in', 'the', 'room', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'garlic', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'out', 'of', 'the', 'ball', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'the', 'hand', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'sat', 'in', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'mine', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'go', 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['the', 'dog', 'is', 'your', 'way', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'was', 'no', 'bad', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 4/20 loss: 1.2332 - acc: 0.7607 - val_loss: 1.2996 - val_acc: 0.7643\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'relieved', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"can't\", 'be', 'sure', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['what', 'is', 'so', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'always', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'liked', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'can', 'be', 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"isn't\", 'crying', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'to', 'die', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'threatened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'a', 'nice', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'like', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'cookies', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'out', 'of', 'the', 'water', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'do', 'this', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'playing', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'in', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'try', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['the', 'dog', 'is', 'your', 'head', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'made', 'me', 'money', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 5/20 loss: 1.0578 - acc: 0.7860 - val_loss: 1.2045 - val_acc: 0.7797\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'embarrassed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"can't\", 'be', 'sure', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'happened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"doesn't\", 'like', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'sure', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'naive', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'a', 'idiot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'look', 'like', 'a', 'fever', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'garlic', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'the', 'hands', 'closed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'will', 'come', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['write', 'it', 'up', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'playing', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'mine', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'try', 'to', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"tom's\", 'mother', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'has', 'no', 'hair', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 6/20 loss: 0.9090 - acc: 0.8099 - val_loss: 1.1026 - val_acc: 0.7984\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'embarrassed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"don't\", 'want', 'to', 'stop', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'happened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'afraid', 'of', 'boston', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'wrong', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'be', 'fired', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'caught', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'threatened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'out', 'of', 'love', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'the', 'band', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'fanatics', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'the', 'garbage', 'on', 'the', 'train', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'will', 'get', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'this', 'easy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'sat', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'mine', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'to', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['my', 'dog', 'is', 'running', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'rained', 'hard', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 7/20 loss: 0.7790 - acc: 0.8329 - val_loss: 1.0331 - val_acc: 0.8122\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'embarrassed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', \"don't\", 'want', 'to', 'die', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'he', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'still', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'be', 'shot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'like', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'threatened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'moving', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'carrots', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'the', 'hands', 'inside', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'will', 'leave', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['hand', 'it', 'to', 'get', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'spoke', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'try', 'to', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'at', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'rained', 'fast', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 8/20 loss: 0.6674 - acc: 0.8536 - val_loss: 0.9729 - val_acc: 0.8238\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'embarrassed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'he', 'coming', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'did', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'have', 'a', 'thing', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'care', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'welcomed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'moving', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'chess', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'the', 'hands', 'off', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['fill', 'this', 'for', 'these', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'approached', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['go', 'your', 'son', 'driver', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'rained', 'heavily', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 9/20 loss: 0.5711 - acc: 0.8726 - val_loss: 0.9235 - val_acc: 0.8338\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'annoyed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'he', 'afraid', 'of', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'he', 'is', 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'find', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'care', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'threatened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'cool', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'like', 'a', 'thief', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'westerns', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'the', 'windows', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['cover', 'up', 'this', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'terrified', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'belt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'rained', 'three', 'ago', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 10/20 loss: 0.4884 - acc: 0.8895 - val_loss: 0.8949 - val_acc: 0.8405\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'awkward', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'happened', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'from', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"isn't\", 'fired', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'feel', 'like', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'welcomed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'cool', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'cities', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'this', 'back', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'spoke', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'belt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'not', 'mayor', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 11/20 loss: 0.4173 - acc: 0.9053 - val_loss: 0.8601 - val_acc: 0.8489\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'annoyed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'her', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"doesn't\", 'have', 'a', 'thing', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'hate', 'them', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['let', 'it', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'trains', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'up', 'at', 'guard', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'take', 'this', 'back', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'rescued', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tuck', 'your', 'son', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'has', 'no', 'money', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 12/20 loss: 0.3563 - acc: 0.9186 - val_loss: 0.8456 - val_acc: 0.8523\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'annoyed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'he', 'is', 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'hate', 'them', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['let', 'it', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'mahjong', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['please', 'take', 'it', 'again', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'brought', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'old', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'rained', 'every', 'day', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 13/20 loss: 0.3046 - acc: 0.9302 - val_loss: 0.8375 - val_acc: 0.8559\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'was', 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"isn't\", 'hurt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'even', 'even', 'tried', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['calm', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'mahjong', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'take', 'this', 'this', 'way', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'terrified', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tuck', 'your', 'shoe', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'no', 'mayor', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 14/20 loss: 0.2596 - acc: 0.9400 - val_loss: 0.8200 - val_acc: 0.8597\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'her', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'what', 'is', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"didn't\", 'have', 'a', 'thing', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'welcomed', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'a', 'taste', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'prunes', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'up', 'crying', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['check', 'this', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'rescued', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['go', 'your', 'old', 'mouth', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'no', 'brothers', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 15/20 loss: 0.2220 - acc: 0.9485 - val_loss: 0.8151 - val_acc: 0.8626\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'allowed', 'of', 'a', 'hurry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', \"it's\", 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'hate', 'them', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['calm', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'hedgehogs', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['cover', 'this', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'approached', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['come', 'help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tuck', 'your', 'shirt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'no', 'mayor', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 16/20 loss: 0.1904 - acc: 0.9553 - val_loss: 0.8139 - val_acc: 0.8635\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'her', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'still', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'knows', 'a', 'reason', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'even', 'even', 'tried', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['calm', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'prunes', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['cover', 'this', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'rescued', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['help', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'seconds', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'no', 'mayor', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 17/20 loss: 0.1629 - acc: 0.9618 - val_loss: 0.8183 - val_acc: 0.8641\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'exhausted', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', \"what's\", 'right', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"doesn't\", 'bite', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'even', 'agree', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'a', 'taste', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'prunes', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['check', 'this', 'down', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'approached', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tuck', 'your', 'shirt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"there's\", 'no', 'more', 'ideas', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 18/20 loss: 0.1407 - acc: 0.9665 - val_loss: 0.8194 - val_acc: 0.8658\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'a', 'mind', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', 'who', 'is', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['let', 'it', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'weddings', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['check', 'this', 'out', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'approached', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"everyone's\", 'there', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'no', 'mayor', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 19/20 loss: 0.1226 - acc: 0.9704 - val_loss: 0.8202 - val_acc: 0.8673\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'just', 'angry', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', \"it's\", 'wrong', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', \"doesn't\", 'have', 'a', 'thing', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'even', 'remember', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['let', 'it', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'westerns', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'sound', 'to', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['check', 'this', 'out', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'rescued', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tuck', 'your', 'belt', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"there's\", 'no', 'trouble', 'left', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "Epoch 20/20 loss: 0.1080 - acc: 0.9734 - val_loss: 0.8282 - val_acc: 0.8675\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'semble', 'malheureux']\n",
            "['tom', 'looks', 'miserable', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'looks', 'miserable', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'ne', 'savons', 'vraiment', 'pas']\n",
            "['we', 'really', \"don't\", 'know', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'really', \"don't\", 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'à', \"l'évidence\", 'il', 'ment']\n",
            "['obviously', 'he', 'is', 'lying', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'she', 'afraid', 'of', 'her', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'est\", 'plus', 'en', 'colère']\n",
            "['tom', 'is', 'no', 'longer', 'angry', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'from', 'nervous', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'fait', 'cela']\n",
            "[\"i've\", 'done', 'that', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'did', 'that', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'sait', \"qu'il\", 'a', 'raison']\n",
            "['tom', 'knows', \"he's\", 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'knows', \"it's\", 'wrong', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', \"n'a\", 'pas', 'de', 'regrets']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'no', 'regrets', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ne', 'le', 'hais', 'pas']\n",
            "['i', \"don't\", 'hate', 'him', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'even', 'like', 'them', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'ai\", 'été', 'incarcérée']\n",
            "['i', 'was', 'detained', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'was', 'beaten', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tranquille']\n",
            "['take', 'it', 'easy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'it', 'easy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'étais', 'dans', 'le', 'coma']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'were', 'in', 'a', 'coma', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"j'aime\", 'les', 'mûres']\n",
            "['i', 'love', 'blackberries', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'like', 'westerns', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'gardez', 'la', 'tête', 'basse']\n",
            "['keep', 'your', 'head', 'low', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['keep', 'your', 'head', 'low', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'le', 'mérites']\n",
            "['it', 'serves', 'you', 'right', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'deserve', 'him', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'UNK', 'ce', 'chèque']\n",
            "['endorse', 'this', 'check', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['check', 'this', 'out', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'a', 'recommandé', 'marie']\n",
            "['tom', 'recommended', 'mary', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'teaches', 'mary', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tout', 'le', 'monde', 'est', 'là']\n",
            "[\"everybody's\", 'here', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['everyone', 'is', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'excusez', 'moi']\n",
            "['excuse', 'me', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['excuse', 'me', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'prends', 'tes', 'jambes', 'à', 'ton', 'cou']\n",
            "['run', 'for', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['take', 'your', 'seat', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'il', 'ne', 'reste', 'aucune', 'nourriture']\n",
            "[\"there's\", 'no', 'food', 'left', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"there's\", 'no', 'milk', 'left', 'STOP']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRq_K6F4rHNj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}