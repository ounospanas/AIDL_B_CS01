{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers #4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "scientific-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "described-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==\"4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-romantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B, I, O, O, O]</td>\n",
       "      <td>[Set, up, was, easy, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
       "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[This, hardware, seems, to, be, better, than, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, 'm, done, with, WinDoze, computers, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B, ...</td>\n",
       "      <td>[I, 've, had, it, for, about, 2, months, now, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>[O, O, O, O, O, O, O, B, I, O]</td>\n",
       "      <td>[the, latest, version, does, not, have, a, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>[B, O, O, O, O, O, O, O, O, B, O, O, O, O, O, O]</td>\n",
       "      <td>[Screen, -, although, some, people, might, com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  \\\n",
       "0        [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1    [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                                [O, O, O, O, O, O, O]   \n",
       "3                                      [B, I, O, O, O]   \n",
       "4                    [O, O, O, O, O, B, I, O, B, I, O]   \n",
       "..                                                 ...   \n",
       "795  [O, B, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "796                              [O, O, O, O, O, O, O]   \n",
       "797  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B, ...   \n",
       "798                     [O, O, O, O, O, O, O, B, I, O]   \n",
       "799   [B, O, O, O, O, O, O, O, O, B, O, O, O, O, O, O]   \n",
       "\n",
       "                                              sentence  \n",
       "0    [Boot, time, is, super, fast, ,, around, anywh...  \n",
       "1    [tech, support, would, not, fix, the, problem,...  \n",
       "2          [but, in, resume, this, computer, rocks, !]  \n",
       "3                              [Set, up, was, easy, .]  \n",
       "4    [Did, not, enjoy, the, new, Windows, 8, and, t...  \n",
       "..                                                 ...  \n",
       "795  [This, hardware, seems, to, be, better, than, ...  \n",
       "796         [I, 'm, done, with, WinDoze, computers, .]  \n",
       "797  [I, 've, had, it, for, about, 2, months, now, ...  \n",
       "798  [the, latest, version, does, not, have, a, dis...  \n",
       "799  [Screen, -, although, some, people, might, com...  \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('ae/laptop/test.json').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "purple-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch\n",
    "\n",
    "label_list = ['O','B','I']\n",
    "label_encoding_dict = {'I': 2, 'O': 0, 'B': 1,}\n",
    "\n",
    "task = \"ner\" \n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def get_all_tokens_and_ner_tags(directory):\n",
    "    df = pd.read_json(directory).transpose().reset_index().drop('index', axis=1)\n",
    "    df = df.rename(columns={\"sentence\": \"tokens\", \"label\": \"ner_tags\"})\n",
    "    return df\n",
    "    \n",
    "#     return pd.concat([get_tokens_and_ner_tags(os.path.join(directory, filename)) for filename in \n",
    "#                       os.listdir(directory)]).reset_index().drop('index', axis=1)\n",
    "    \n",
    "def get_tokens_and_ner_tags(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == '\\n') if not x]\n",
    "        tokens = [[x.split('\\t')[0] for x in y] for y in split_list]\n",
    "        entities = [[x.split('\\t')[1][:-1] for x in y] for y in split_list] \n",
    "    return pd.DataFrame({'tokens': tokens, 'ner_tags': entities})\n",
    "  \n",
    "def get_un_token_dataset(train_directory, test_directory):\n",
    "    train_df = get_all_tokens_and_ner_tags(train_directory)\n",
    "    test_df = get_all_tokens_and_ner_tags(test_directory)\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    return (train_dataset, test_dataset)\n",
    "\n",
    "train_dataset, test_dataset = get_un_token_dataset('ae/rest16/train.json', \n",
    "                                                   'ae/rest16/test.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_and_align_labels at 0x7f472f3a8670> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52206476ebc74df9b8ed580b545f1327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdb2622002c49e29ba826f6d91cb9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    label_all_tokens = True\n",
    "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif label[word_idx] == '0':\n",
    "                label_ids.append(0)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-brook",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "defensive-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='232' max='232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [232/232 00:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113234</td>\n",
       "      <td>0.668432</td>\n",
       "      <td>0.799747</td>\n",
       "      <td>0.728217</td>\n",
       "      <td>0.954063</td>\n",
       "      <td>1.182000</td>\n",
       "      <td>571.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.767824</td>\n",
       "      <td>0.956580</td>\n",
       "      <td>1.186300</td>\n",
       "      <td>569.823000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 116 < 548; dropping {'eval/loss': 0.11323434859514236, 'eval/precision': 0.6684322033898306, 'eval/recall': 0.7997465145754119, 'eval/f1': 0.7282169648009233, 'eval/accuracy': 0.9540632865875585, 'eval/runtime': 1.182, 'eval/samples_per_second': 571.912, 'train/epoch': 1.0}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 232 < 548; dropping {'eval/loss': 0.10839812457561493, 'eval/precision': 0.7394366197183099, 'eval/recall': 0.7984790874524715, 'eval/f1': 0.7678244972577697, 'eval/accuracy': 0.9565803667745415, 'eval/runtime': 1.1863, 'eval/samples_per_second': 569.823, 'train/epoch': 2.0}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 232 < 548; dropping {'train/train_runtime': 23.6977, 'train/train_samples_per_second': 9.79, 'train/total_flos': 98848705439160, 'train/epoch': 2.0}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 232 < 549; dropping {'eval/loss': 0.10839812457561493, 'eval/precision': 0.7394366197183099, 'eval/recall': 0.7984790874524715, 'eval/f1': 0.7678244972577697, 'eval/accuracy': 0.9565803667745415, 'eval/runtime': 1.1953, 'eval/samples_per_second': 565.544, 'train/epoch': 2.0}.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"test-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \n",
    "            \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_tokenized_datasets,\n",
    "    eval_dataset=test_tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "trainer.save_model('rest16_bert.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-tracker",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reflected-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./rest16_bert.model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "commercial-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('./rest16_bert.model/', num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "australian-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in test_tokenized_datasets:\n",
    "        res = list(np.argmax(model.forward(torch.tensor(i['input_ids']).unsqueeze(0).to('cpu'), \n",
    "                      torch.tensor(i['attention_mask']).unsqueeze(0).to('cpu'))[0][0].numpy()[1:-1],1))\n",
    "        resint = [int(arg) for arg in res]\n",
    "        results.append(resint)\n",
    "        labels.append(list(np.array(i['labels'][1:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adolescent-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "armed-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps({\"rest16_bert_base_preds\":results})\n",
    "with open('rest16_bert_base_preds.json', 'w') as outfile:\n",
    "    outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-ethiopia",
   "metadata": {},
   "source": [
    "### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "modified-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in test_tokenized_datasets:\n",
    "        results+=list(np.argmax(model.forward(torch.tensor(i['input_ids']).unsqueeze(0).to('cpu'), \n",
    "                      torch.tensor(i['attention_mask']).unsqueeze(0).to('cpu'))[0][0].numpy()[1:-1],1))\n",
    "        labels+=list(np.array(i['labels'][1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lovely-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civic-organizer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696753195205208"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels,results,labels =[1,2],average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lesser-communications",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9702,  155,  101],\n",
       "       [ 116,  655,   18],\n",
       "       [  77,   16,  284]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-commercial",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beginning-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import json\n",
    "\n",
    "def get_chunk_type(tok, idx_to_tag):\n",
    "\n",
    "    tag_name = idx_to_tag[tok]\n",
    "    tag_class = tag_name.split('-')[0]\n",
    "    tag_type = tag_name.split('-')[-1]\n",
    "    return tag_class, tag_type\n",
    "\n",
    "\n",
    "def get_chunks(seq, tags,message=None):\n",
    "\n",
    "    default = tags['O']\n",
    "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
    "    chunks = []\n",
    "    chunk_type, chunk_start = None, None\n",
    "    for i, tok in enumerate(seq):\n",
    "        # End of a chunk 1\n",
    "        if tok == default and chunk_type is not None:\n",
    "            # Add a chunk.\n",
    "            chunk = (chunk_type, chunk_start, i)\n",
    "            chunks.append(chunk)\n",
    "            chunk_type, chunk_start = None, None\n",
    "\n",
    "        # End of a chunk + start of a chunk!\n",
    "        elif tok != default:\n",
    "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag)\n",
    "            if chunk_type is None:\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "            elif tok_chunk_type != chunk_type or tok_chunk_class == 'B':\n",
    "                chunk = (chunk_type, chunk_start, i)\n",
    "                chunks.append(chunk)\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # end condition\n",
    "    if chunk_type is not None:\n",
    "        chunk = (chunk_type, chunk_start, len(seq))\n",
    "        chunks.append(chunk)\n",
    "    #print(message + \"{}{}{}\".format(seq, tags, chunks))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def run_evaluate(labels, labels_pred, sequence_lengths):\n",
    "\n",
    "    accs = []\n",
    "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "    gold = []\n",
    "    pred = []\n",
    "    acc_list = []\n",
    "\n",
    "    for lab, lab_pred, length in zip(labels, labels_pred,\n",
    "                                        sequence_lengths):\n",
    "        lab      = lab[:length]\n",
    "        lab_pred = lab_pred[:length]\n",
    "        acc_list.append(lab==lab_pred)\n",
    "        gold+=lab\n",
    "        pred+=lab_pred\n",
    "        accs    += [a==b for (a, b) in zip(lab, lab_pred)]\n",
    "#         lab_chunks      = set(get_chunks(lab, config.vocab_tags,message = \"gold standard\"))\n",
    "#         #tmp_lab_chunks.append(lab_chunks)\n",
    "#         lab_pred_chunks = set(get_chunks(lab_pred,config.vocab_tags,message = \"prediction\"))\n",
    "#         #tmp_lab_pred_chunks.append(lab_pred_chunks)\n",
    "#         correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "#         total_preds   += len(lab_pred_chunks)\n",
    "#         total_correct += len(lab_chunks)\n",
    "\n",
    "#     p   = correct_preds / total_preds if correct_preds > 0 else 0\n",
    "#     r   = correct_preds / total_correct if correct_preds > 0 else 0\n",
    "#     f1  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "\n",
    "    acc = np.mean(accs)\n",
    "\n",
    "    #include 1,2\n",
    "    score = precision_recall_fscore_support(gold, pred, labels =[1,2], average='macro')\n",
    "    #include 0,1,2\n",
    "    score_0 = precision_recall_fscore_support(gold, pred, average='macro')\n",
    "\n",
    "    return acc, [\"{0:.5f}\".format(x) for x in score[:3]], [\"{0:.5f}\".format(x) for x in score_0[:3]], acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sexual-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(x) for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afraid-clause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9565803667745415,\n",
       " ['0.74885', '0.79174', '0.76968'],\n",
       " ['0.82606', '0.85259', '0.83891'],\n",
       " [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluate(labels, results, sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-keeping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
